{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af1b53",
   "metadata": {},
   "source": [
    "## Загрузим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea38a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import gc\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894781b",
   "metadata": {},
   "source": [
    "## А сюда необходимые нам классы и функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a88b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_type,):\n",
    "       \n",
    "        if dataset_type == 'train':\n",
    "            file = 'ranking_train.jsonl'\n",
    "        else:\n",
    "            file = 'ranking_test.jsonl'\n",
    "        f = open(file, 'r')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "        self.lines = []\n",
    "        for i in range(len(lines)):\n",
    "            line = json.loads(lines[i])\n",
    "            self.lines.append(line)\n",
    "        print('Количество topics в', dataset_type, ':', len(self.lines))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lines = self.lines[idx]\n",
    "\n",
    "    \n",
    "        sample = {\n",
    "            'topic': lines['text'],\n",
    "            'comments': lines['comments'],\n",
    "        }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e77dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    '''\n",
    "      Класс сети обучения\n",
    "      на вход принимает: сеть получения эмбеддингов\n",
    "      на выходе: эмбеддинг якоря и после линейного слоя классификации\n",
    "    '''\n",
    "    def __init__(self, EmbeddingNet):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.embeddingLayer = EmbeddingNet\n",
    "        self.classifierLayer = nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, topic, topic_attention_mask, comment, comment_attention_mask):\n",
    "        topic_em = self.embeddingLayer(topic, attention_mask = topic_attention_mask, return_dict=False)\n",
    "        comment_em = self.embeddingLayer(comment, attention_mask = comment_attention_mask, return_dict=False)\n",
    "#         print(type(comment_em))\n",
    "        logits = self.classifierLayer(comment_em[0][:, 0, :])\n",
    "        return topic_em[0][:, 0, :], comment_em[0][:, 0, :], logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e384574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss():\n",
    "    '''\n",
    "      Функция получения сводного лосса по модели\n",
    "      на вход принимает: функцию определения расстояние м/у векторами, значение допуска и обмена\n",
    "      на выходе: сводный лосс\n",
    "    '''\n",
    "    loss1 = nn.CosineEmbeddingLoss()\n",
    "    loss2 = nn.CrossEntropyLoss()\n",
    "    def helper(topic, comment, logits, score):\n",
    "        '''\n",
    "          Функция лоссов по модели\n",
    "          на вход принимает: эмбеддинги (якорь, позитивный и негативный) и конечный с линейного слоя\n",
    "          на выходе: результат сводного лосса\n",
    "        '''\n",
    "#         print(loss1(topic, comment) + loss2(logits, score))\n",
    "        return loss1(topic, comment, score) + loss2(logits, score)\n",
    "    return helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2a88545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text).strip()\n",
    "    \n",
    "    # Удаляем html теги\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    \n",
    "    # Удаляем единичные символы\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    \n",
    "    # Удаляем единычные символы из начала строки\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
    "    \n",
    "    # Заменяем несколько пробелов на один\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    \n",
    "    # Удаляем 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16fddc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_files, val_files, model, epochs, batch_size, optimizer=None, criterion=None, sheduler=None):\n",
    "    '''\n",
    "    Функция обучения по эпохам\n",
    "    принимает на вход: даталоадер с тренировочными данными, даталоадер с проверочными данными ,модель,\n",
    "    количество эпох обучения, размер батча, оптимайзер, функцию потерь, планировщик\n",
    "    отдает: лучшую модель на обучении, историю обучения\n",
    "    '''        \n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters()) # будем использовать модель Adam\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss() # будем использовать кросэнтропию\n",
    "    \n",
    "    best_model = model.state_dict() # сохраняем все тензоры модели\n",
    "    best_acc = 0.0 # для понимания лучшего скора модели\n",
    "    \n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "        opt = torch.optim.Adam(model.parameters())\n",
    "        criterion = criterion\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_acc, train_loss = fit_epoch(model, train_loader, criterion, opt, sheduler)\n",
    "            print(\"loss\", train_loss)\n",
    "            \n",
    "            val_acc, val_loss = eval_epoch(model, val_loader, criterion)\n",
    "            history.append((epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "            \n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_model = model.state_dict()\n",
    "                            \n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "    \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a35a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, loss_fn, optimizer, sheduler=None):\n",
    "    '''\n",
    "    Функция обучения на эпохе\n",
    "    принимает на вход: модель, даталоадер, функцию потерь, функцию оптимизатора и планировщика\n",
    "    отдает: масив метрики accuracy, средний лосс по эпохе\n",
    "    '''\n",
    "    losses = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_elements = 0\n",
    "    \n",
    "    model.train(True) # так как нам необходимо оптимизировать данные на train\n",
    "    \n",
    "    for i, batch in enumerate(train_loader):\n",
    "        tokenized_topic = [tokenizer.encode(\n",
    "                clear_text(batch[k]['topic']),\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len) for k in range(len(batch))]\n",
    "        padded_topic = np.array([i + [0]*(max_len - len(i)) for i in tokenized_topic])\n",
    "        topic_attention_mask = np.where(padded_topic != 0, 1, 0)\n",
    "\n",
    "        tokenized_comments = [tokenizer.encode(\n",
    "                clear_text(batch[j]['comments'][k]['text']),\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len) for j in range(len(batch)) for k in range(len(batch[j]['comments']))]\n",
    "        padded_comments = np.array([i + [0]*(max_len - len(i)) for i in tokenized_comments])\n",
    "        comments_attention_mask = np.where(padded_comments != 0, 1, 0)\n",
    "        score = np.array([\n",
    "            batch[j]['comments'][k]['score'] for j in range(len(batch)) for k in range(len(batch[j]['comments']))\n",
    "        ])      \n",
    "        \n",
    "        num_elements += score.shape[0]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        topic, comments, logits = model(\n",
    "            torch.LongTensor(padded_topic).to(device),\n",
    "            torch.LongTensor(topic_attention_mask).to(device),\n",
    "            torch.LongTensor(padded_comments).to(device),\n",
    "            torch.LongTensor(comments_attention_mask).to(device)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss_fn(\n",
    "            torch.repeat_interleave(topic, CLASS_COUNT, dim=0),\n",
    "            comments,\n",
    "            logits,\n",
    "            torch.LongTensor(score).to(device)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        num_correct += torch.sum(y_pred.cpu() == torch.LongTensor(score))\n",
    "        \n",
    "    if sheduler is not None: # проверяем нужна ли нам оптимизация\n",
    "        sheduler.step() # если да, то делаем шаг оптимизации\n",
    "    \n",
    "    accuracy = num_correct / num_elements\n",
    "    \n",
    "    return accuracy.numpy(), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dac8b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataloader, loss_fn):\n",
    "    '''\n",
    "    Функция проверки обучения на эпохе\n",
    "    принимает на вход: модель, даталоадер, функцию потерь\n",
    "    отдает: масив метрики accuracy, средний лосс по эпохе\n",
    "    '''    \n",
    "    losses = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_elements = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        \n",
    "        tokenized_topic = [tokenizer.encode(\n",
    "                clear_text(batch[k]['topic']),\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len) for k in range(len(batch))]\n",
    "        padded_topic = np.array([i + [0]*(max_len - len(i)) for i in tokenized_topic])\n",
    "        topic_attention_mask = np.where(padded_topic != 0, 1, 0)\n",
    "\n",
    "        tokenized_comments = [tokenizer.encode(\n",
    "                clear_text(batch[j]['comments'][k]['text']),\n",
    "                add_special_tokens=True,\n",
    "                truncation=True,\n",
    "                max_length=max_len) for j in range(len(batch)) for k in range(len(batch[j]['comments']))]\n",
    "        padded_comments = np.array([i + [0]*(max_len - len(i)) for i in tokenized_comments])\n",
    "        comments_attention_mask = np.where(padded_comments != 0, 1, 0)\n",
    "        score = np.array([\n",
    "            batch[j]['comments'][k]['score'] for j in range(len(batch)) for k in range(len(batch[j]['comments']))\n",
    "        ])      \n",
    "        \n",
    "        num_elements += score.shape[0]        \n",
    "        with torch.no_grad():\n",
    "            topic, comments, logits = model(\n",
    "                torch.LongTensor(padded_topic).to(device),\n",
    "                torch.LongTensor(topic_attention_mask).to(device),\n",
    "                torch.LongTensor(padded_comments).to(device),\n",
    "                torch.LongTensor(comments_attention_mask).to(device)\n",
    "            )\n",
    "            \n",
    "            loss = loss_fn(\n",
    "                torch.repeat_interleave(topic, 5, dim=0),\n",
    "                comments,\n",
    "                logits,\n",
    "                torch.LongTensor(score).to(device)\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            num_correct += torch.sum(y_pred.cpu() == torch.LongTensor(score))\n",
    "    \n",
    "    accuracy = num_correct / num_elements\n",
    "            \n",
    "    return accuracy.numpy(), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d72e3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn):\n",
    "    '''\n",
    "    Функция проверки обучения\n",
    "    принимает на вход: модель, даталоадер с проверочными данными, функцию потерь\n",
    "    отдает: масив метрики accuracy, средний лосс по проверке\n",
    "    '''       \n",
    "    losses = []\n",
    "\n",
    "    num_correct = 0\n",
    "    num_elements = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in tqdm(enumerate(dataloader), desc='Test images'):\n",
    "        \n",
    "        X_batch, y_batch = batch['image'], batch['label']\n",
    "        num_elements += len(y_batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            logits = model(X_batch.to(device))\n",
    "            \n",
    "            loss = loss_fn(logits, y_batch.to(device))\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            num_correct += torch.sum(y_pred.cpu() == y_batch)\n",
    "    \n",
    "    accuracy = num_correct / num_elements\n",
    "            \n",
    "    return accuracy.numpy(), np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72675c41",
   "metadata": {},
   "source": [
    "## Посмотрим, что из себя представляют наши данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "188247e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\":\"iOS 8.0.1 released, broken on iPhone 6 models, withdrawn\",\"comments\":[{\"text\":\"I&#x27;m still waiting for them to stabilize wifi on the iPad sith iOS 8. Their quality has really started to slip for me since 10.9 on Mac.\",\"score\":null},{\"text\":\"For those who upgraded, no need to do a restore. You can just option-click &quot;Update&quot; and downgrade the OS back to 8.0.0.Instructions: https:&#x2F;&#x2F;gist.github.com&#x2F;locriani&#x2F;f0f5f4f71a28945c3750\",\"score\":null},{\"text\":\"Upgraded shortly after it was released and suffered the consequences.  Just was able to restore back down to 8.0I had to turn iMessage off and back on again in order for Apple to re-register my number... until then I was unable to send to any existing contacts.\",\"score\":null},{\"text\":\"I think they were under a lot of pressure on the HealthKit front.  That was one of their big flagship iOS 8 features, they got all these app developers to integrate it, then iOS 8 shipped and they had a showstopper bug and wouldn&#x27;t release any apps using HealthKit.\",\"score\":null},{\"text\":\"Fix for those who already updated:  http:&#x2F;&#x2F;www.imore.com&#x2F;ios-801-kill-touch-id-and-cell-service-...\",\"score\":null}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('ranking_test.jsonl', 'r'):\n",
    "    print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3c97",
   "metadata": {},
   "source": [
    "Мы имеем topic и комментарии к нему с оценкой значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343a519",
   "metadata": {},
   "source": [
    "Посмотрим, сколько всего топиков и комментариев к ним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95e38a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество топиков 88107\n",
      "Количество комментов в топике {5}\n",
      "Количество рангов в комментах {5}\n",
      "Коммент максимального размера: 43302\n"
     ]
    }
   ],
   "source": [
    "max_len_comment = 0\n",
    "num_topic = 0\n",
    "num_comments = []\n",
    "for line in open('ranking_train.jsonl', 'r'):\n",
    "    topic = json.loads(line)['text']\n",
    "    num_topic += 1\n",
    "    comments = json.loads(line)['comments']\n",
    "    num_comments.append(len(comments))\n",
    "    text = [comments[i]['text'] for i in range(len(comments))]\n",
    "    for com in text:\n",
    "        if len(com) > max_len_comment:\n",
    "            max_len_comment = len(com)\n",
    "\n",
    "idx_train = [i for i in range(num_topic)]\n",
    "print('Количество топиков', num_topic)\n",
    "print('Количество комментов в топике', set(num_comments))\n",
    "print('Количество рангов в комментах', set(num_comments))\n",
    "print('Коммент максимального размера:', max_len_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a1b3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Определение количества классов\n",
    "CLASS_COUNT = max(list(set(num_comments)))\n",
    "CLASS_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c3157",
   "metadata": {},
   "source": [
    "В train данных у нас 88107 топиков и по 5 комментариев к ним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14cd925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество топиков 14004\n",
      "Количество комментов в топике {5}\n",
      "Количество рангов в комментах {5}\n",
      "Коммент максимального размера: 662\n"
     ]
    }
   ],
   "source": [
    "max_len_comment = 0\n",
    "num_topic = 0\n",
    "num_comments = []\n",
    "for line in open('ranking_test.jsonl', 'r'):\n",
    "    topic = json.loads(line)['text']\n",
    "    num_topic += 1\n",
    "    comments = json.loads(line)['comments']\n",
    "    num_comments.append(len(comments))\n",
    "    for com in text:\n",
    "        if len(com) > max_len_comment:\n",
    "            max_len_comment = len(com)\n",
    "\n",
    "idx_train = [i for i in range(num_topic)]\n",
    "print('Количество топиков', num_topic)\n",
    "print('Количество комментов в топике', set(num_comments))\n",
    "print('Количество рангов в комментах', set(num_comments))\n",
    "print('Коммент максимального размера:', max_len_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c2243",
   "metadata": {},
   "source": [
    "В test данных у нас 14004 топика и по 5 комментариев к ним. Одинаковое количество что в train, что в test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d82b60",
   "metadata": {},
   "source": [
    "В некоторых комментариях присутствуют ссылки, посмотрим на них внимательно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "039a281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('ranking_train.jsonl', 'r'):\n",
    "    topic = json.loads(line)['text']\n",
    "    comments = json.loads(line)['comments']\n",
    "    comment = [comments[i]['text'] for i in range(len(comments))]\n",
    "    score = [comments[i]['score'] for i in range(len(comments))]\n",
    "    columns = ['url', 'num_url', 'score']\n",
    "    for com in range(len(comment)):\n",
    "        url = re.findall(r'(https?:[^\\s]+)', comment[com])\n",
    "        if url != []:\n",
    "            row = [1, len(url), score[com]]\n",
    "        else:\n",
    "            row = [0, 0, score[com]]\n",
    "        with open('df_train.json', 'a') as file:\n",
    "            json.dump(row, file)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "224681b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>num_url</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762135</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1762140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         url  num_url  score\n",
       "0          0        0      0\n",
       "1          0        0      1\n",
       "2          0        0      2\n",
       "3          0        0      3\n",
       "4          0        0      4\n",
       "...      ...      ...    ...\n",
       "1762135    1        1      0\n",
       "1762136    0        0      1\n",
       "1762137    0        0      2\n",
       "1762138    0        0      3\n",
       "1762139    0        0      4\n",
       "\n",
       "[1762140 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_json('df_train.json', lines = True)\n",
    "df_train.columns = ['url', 'num_url', 'score']\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1056af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# сгруппируем таблицу по 'score' со значениями количеств ссылок\n",
    "df_score = df_train.groupby ('score')['num_url'].mean ()\n",
    "\n",
    "# построим график\n",
    "df_score.plot (kind = 'bar', y = 'num_url', style = 'o-', xlim = (0, 38), grid = True, figsize = (15, 5))\n",
    "\n",
    "#подписи к графику\n",
    "plt.title ('Гистограмма среднего количества ссылок по рангу комментария')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9fa71a",
   "metadata": {},
   "source": [
    "Видим, что чем больше количество комментариев в комментах, ранг коммента ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b84d1",
   "metadata": {},
   "source": [
    "## Выбор и обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53918205",
   "metadata": {},
   "source": [
    "Попробовал такие модели как:\n",
    "\n",
    "BERT - слишком тяжелая, не для моей машины\n",
    "\n",
    "GPT-3 - не понравилось долгое обучение\n",
    "\n",
    "XLNet - Не успел попробовать\n",
    "\n",
    "DistilBert - меньше BERT и легче настраивается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f760914",
   "metadata": {},
   "source": [
    "Попробум обучить нашу модель DistilBertModel.\n",
    "\n",
    "Загрузим саму модель (уже раее обученную), токенизатор и веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e154c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizer,\n",
    "    'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model_BERT = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e213106",
   "metadata": {},
   "source": [
    "Если нам позволет железо, а оно позволяет, то обучим на CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4217720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e2bd87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 19 07:22:17 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0  On |                  N/A |\r\n",
      "| 30%   41C    P8    24W / 220W |   6083MiB /  8192MiB |     19%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2008      G   /usr/lib/xorg/Xorg                144MiB |\r\n",
      "|    0   N/A  N/A      2176      G   /usr/bin/gnome-shell               38MiB |\r\n",
      "|    0   N/A  N/A      3653      G   ...983217536564232705,131072       97MiB |\r\n",
      "|    0   N/A  N/A      9934      G   .../usr/bin/telegram-desktop        3MiB |\r\n",
      "|    0   N/A  N/A     12018      C   /usr/bin/python3                 5794MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772622eb",
   "metadata": {},
   "source": [
    "Вот как выглядит наша сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "297958a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed726aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_BERT.output_layer_norm = nn.Sequential(\n",
    "    nn.LayerNorm(768),\n",
    "    nn.BatchNorm1d(768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deae058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dbdb8a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38ba91",
   "metadata": {},
   "source": [
    "Сделаем свой Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be934bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество topics в train : 88107\n",
      "Количество topics в test : 14004\n"
     ]
    }
   ],
   "source": [
    "train_data = MyDataset('train')\n",
    "test_data = MyDataset('test')\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "test_size = len(train_data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_data, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "237cb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим максимальную длину нашиз паддингов из комментов\n",
    "max_len = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06bb27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для получения эмбеддингов из текста\n",
    "embeddingNetwork = model_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97217b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My_Model(\n",
       "  (embeddingLayer): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layer_norm): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (classifierLayer): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# И модель классификации\n",
    "classifierNetWork = My_Model(embeddingNetwork)\n",
    "classifierNetWork.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "236950e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = custom_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96e4e8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e837ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(classifierNetWork.parameters(), lr=1e-4, betas=(0.9, 0.99)) #добавлено для оптимизации\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) #добавлено для оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5076983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch:   0%|                                              | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.6042399798250269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  12%|████▎                             | 1/8 [33:47<3:56:29, 2027.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001 train_loss: 1.6042     val_loss 2.0681 train_acc 0.2291 val_acc 0.2000\n",
      "loss 1.5886874887164233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  25%|████████                        | 2/8 [1:08:01<3:24:19, 2043.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 002 train_loss: 1.5887     val_loss 1.8982 train_acc 0.2466 val_acc 0.2000\n",
      "loss 1.5868896495712803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  38%|████████████                    | 3/8 [1:42:17<2:50:45, 2049.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 003 train_loss: 1.5869     val_loss 2.1407 train_acc 0.2499 val_acc 0.2000\n",
      "loss 1.5875890023753532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|████████████████                | 4/8 [2:16:36<2:16:51, 2052.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 004 train_loss: 1.5876     val_loss 2.2741 train_acc 0.2480 val_acc 0.2000\n",
      "loss 1.587589066762711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  62%|████████████████████            | 5/8 [2:50:59<1:42:49, 2056.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 005 train_loss: 1.5876     val_loss 2.2237 train_acc 0.2474 val_acc 0.2000\n",
      "loss 1.5841935418978301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  75%|████████████████████████        | 6/8 [3:25:19<1:08:35, 2057.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 006 train_loss: 1.5842     val_loss 2.0452 train_acc 0.2528 val_acc 0.2000\n",
      "loss 1.583597700951143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  88%|█████████████████████████████▊    | 7/8 [3:59:42<34:19, 2059.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 007 train_loss: 1.5836     val_loss 2.2699 train_acc 0.2530 val_acc 0.2000\n",
      "loss 1.5820636939899617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████████████████████████████| 8/8 [4:34:14<00:00, 2056.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 008 train_loss: 1.5821     val_loss 2.4316 train_acc 0.2542 val_acc 0.2000\n",
      "Best val Acc: 0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, history = train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model = classifierNetWork,\n",
    "    epochs = 8,\n",
    "    batch_size = batch_size,\n",
    "    optimizer = optimizer,\n",
    "    sheduler = exp_lr_scheduler,\n",
    "    criterion = loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95b0ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_DistilBert.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dac15835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.load_state_dict(torch.load('model_DistilBert.pth', map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b7f2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, loss, val_loss, acc, val_acc = zip(*history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "828ff9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzIAAAD5CAYAAAD88gDHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6WElEQVR4nO3deXxV1b3//9cnc0LCkAESCBCgyDzVMIkiTggIwle9Fuvcb+V6Ha6193r1tr1qh1+rj95B/TpwqbXUFrFWq2IFx4ooiAoWZFRmCGEIYQwQMn1+f5wDhJAJOcnJSd7Px+M8soe11/6cE8g6n73WXtvcHRERERERkUgSFe4AREREREREzpQSGRERERERiThKZEREREREJOIokRERERERkYijREZERERERCKOEhkREREREYk4MeE6cXp6uufk5ITr9CIiAixdunSPu2eEO46zYWadgeeBTKACmOHuj1cpMwZ4HdgU3PQXd/9ZbfWqnRIRCb/a2qmwJTI5OTksWbIkXKcXERHAzLaEO4YQKAP+xd2/MLMUYKmZvevuq6uU+8jdJ9a3UrVTIiLhV1s7paFlIiIS0dx9h7t/EVw+BKwBOoU3KhERaWhKZEREpNkwsxxgCPBpNbtHmtlyM5tnZv0aNzIREQm1sA0tExERCSUzSwZeAX7g7ger7P4C6OruRWY2AXgN6FlNHdOAaQBdunRp2IBFROSsKJEREZGIZ2axBJKYWe7+l6r7Kyc27j7XzJ42s3R331Ol3AxgBkBubq5Xrae0tJS8vDyKi4tD/h7kpISEBLKzs4mNjQ13KCLShCmRERGRiGZmBvwWWOPu/11DmUxgl7u7mQ0jMLS68EzPlZeXR0pKCjk5OQROK6Hm7hQWFpKXl0e3bt3CHY6INGF13iNjZs+Z2W4zW1lLmTFmtszMVpnZh6ENUUREpFajgBuBi4Nt0TIzm2Bmt5vZ7cEy1wArzWw58AQw1d1P63GpS3FxMWlpaUpiGpCZkZaWpl4vEalTfXpkZgJPEpij/zRm1hZ4Ghjn7lvNrH3IohMREamDu38M1JpZuPuTBNqys6YkpuHpMxaR+qgzkXH3BcFZYGryXQIPFtsaLL87RLHVaPm2/by/djfJ8dEkxcXQKj6aVnExtIoPvuKigz9jSIqPJjZak7OJiIiIiDSWoyXlfLSugC/zDvCvl/dqkHOE4h6Zc4BYM5sPpACPu3u1vTeh8uX2Azzx/rp6l4+LiTotuUmOjyGp0rbjCVBSfMyJBOmUMpUSpMTYaKKidLVIREQa3/79+3nhhRe44447zui4CRMm8MILL9C2bduGCUxEWrzComO8v3Y3767exUfrCiguraB1Qgzfv6AbbZPiQn6+UCQyMcC5wCVAIvCJmS1296+rFgzVtJY3jujK9cO6cKS0nCPHyig6VsaRkvLgzzIOHyvn8LEyDpcc/1nGkWMnlw8fC5TdffDYKceUlFfU6/xmkBR7POkJJjvBnqGk+BiSg8nSyV6ik/sT42KINsMsUI8RWI6y4z8BjCgLdK0bJ/cdLx8VVfm4U8tHVarTqmyLMqDS8inlozj1XJXqiArGAXB8QLk7eHCt6ijz6vadPM5PrJ847kQZr3T86eVPrc8rHXf6vjMf+d70mBH8t2JERxnRFvjdRwXXo4K/v+go0zAMkRZk//79PP3006clMuXl5URHR9d43Ny5cxs6tHqpK04RiSxbCg/z7updvLNqF0u27KXCIatNAt/J7cxlfTMZ3j21wUZHhSKRyQP2uPth4LCZLQAGAaclMnVNa3kmoqKM5GAiEaqbckrKKgJJTUn9EqQjJWUUHQuUPVxSxp6iEg7vPRLYd6ycwyVlVDSDL9TS9B1PeqKCyc7J5dOTnlPKHE+QTpQlWPb4cScTp+MJU3Sl5Cn6eLlg2eOJV+W44OTNCyfX7dT1E4dYvY6rvsypyVyN56q6P7gQvCZwykWCEwl98ICq245fLLAajjtef9SJ8nbymOPHVzmOSmWjqlzwqO64xNhoLuqtWxNbkgceeIANGzYwePBgYmNjSU5OJisri2XLlrF69WqmTJnCtm3bKC4u5p577mHatGkA5OTksGTJEoqKihg/fjznn38+ixYtolOnTrz++uskJiZWe74nnniC6dOnExMTQ9++fXnxxRcpKiri7rvvZsmSJZgZDz30EFdffTWzZ8/ml7/8Je7OFVdcwaOPPgpAcnIyP/zhD3n77bf5r//6LzZv3swTTzxBSUkJw4cP5+mnn1ZyIxIh3J0V2w/wzqpdvLt6F1/tOgRA78wU7rroW4ztl0m/jq0b5SJrKBKZ14EnzSwGiAOGA/8TgnobXVxMFHExcbRNCk197k5xaUWwFyiQCB0tDSQ3FRWB/oeKYPfD8WX34M/g8e5Uu63CT/Y8VAS7Hyoq7zt+LKeWrwh2hZwow+nlK5xTjvVg+Zq+AJ6yrdKXxrq+vFau4/SylfZV+QJKpWNq+7Ia6Z0UFcHfbUWFU17hlAd/F4HlwO+mPLivwgOv8opKx1T+Gfw3FyhLsOzxeoLLFcH6g+sn6nenpKwicEywnuPHV1QuW2m5slp71U5ZP3U/Neyvtc4q20/vtav+uMDnHYyoyv8tr1KuqWmfEs9nP7403GG0SD99YxWr86s+d/Ps9O3Ymocm9au1zCOPPMLKlStZtmwZ8+fP54orrmDlypUnpip+7rnnSE1N5ejRowwdOpSrr76atLS0U+pYt24ds2fP5je/+Q3XXnstr7zyCjfccEON59u0aRPx8fHs378fgJ///Oe0adOGFStWALBv3z7y8/O5//77Wbp0Ke3atWPs2LG89tprTJkyhcOHD9O/f39+9rOfsWbNGh599FEWLlxIbGwsd9xxB7NmzeKmm246y09PRBpKSVkFn24q5J1Vu3hvzS52HCgmymBoTir/MbEvl/XpQJe0EH2BPgN1JjJmNhsYA6SbWR7wEBAL4O7T3X2Nmb0FfAlUAM+6e41TNbckZkZiXDSJcdGkJ8eHOxwROUvHk3qvlOCcTPhrSIBOuUBQ6bhq6jh+MYJK2+s6LjrSM3Y5a8OGDTvleStPPPEEr776KgDbtm1j3bp1pyUy3bp1Y/DgwQCce+65bN68ucb6Bw4cyPXXX8+UKVOYMmUKAO+99x4vvvjiiTLt2rVjwYIFjBkzhoyMDACuv/56FixYwJQpU4iOjubqq68G4P3332fp0qUMHToUgKNHj9K+vXoVRZqaQ8WlzP+qgHdX7+KDtbs5dKyMhNgoLjwng38Z24uLe7cntVXo73s5E/WZtey6epT5NfDrkEQkItJEHR9aV8dMv9JC1NVz0lhatWp1Ynn+/Pm89957fPLJJyQlJTFmzJhqn8cSH3/y4lp0dDRHjx6tsf4333yTBQsWMGfOHH7+85+zatUq3P20YSO1PZYnISHhxNAxd+fmm2/mV7/6Vb3fo4g0jl0HiwP3u6zexScb9lBa7qS1imP8gEzG9s3k/J7pJMQ2nWGgoRhaJiIiIo0kJSWFQ4cOVbvvwIEDtGvXjqSkJNauXcvixYvP6lwVFRVs27aNiy66iPPPP58XXniBoqIixo4dy5NPPsljjz0GBIaWDR8+nHvuuYc9e/bQrl07Zs+ezd13331anZdccgmTJ0/m3nvvpX379uzdu5dDhw7RtWvXs4pVRM6cu7N+dxHvBJOX5dv2A9A1LYlbzsthbL9Mvt2lHdFNdLZeJTIiIiIRJC0tjVGjRtG/f38SExPp0KHDiX3jxo1j+vTpDBw4kF69ejFixIizOld5eTk33HADBw4cwN259957adu2LT/5yU+488476d+/P9HR0Tz00ENcddVV/OpXv+Kiiy7C3ZkwYQKTJ08+rc6+ffvyi1/8grFjx1JRUUFsbCxPPfWUEhmRRlJe4XyxdV9wprGdbC48AsCg7Dbcd3kvLuvbgZ7tkyNiRlSrrSu4IeXm5vqSJUvCcm4REQkws6XunhvuOJqi6tqpNWvW0KdPnzBF1LLosxYJneLScj5et4d3Vu/k/TW7KTxcQmy0MbJHOpf17cBlfTqQ2SYh3GFWq7Z2Sj0yIiIiIiLNzL7DJcGHU+5kwdd7OFpaTkp8DGN6t2ds3w5c2CuD1gmx4Q7zrCiREREREe68804WLlx4yrZ77rmHW2+9NUwRiciZ2rb3CO+s3sW7q3fy+eZ9lFc4ma0TuObcbC7r24ER3dOIi2mYh1OGgxIZERER4amnngp3CCJyhtydVfkHeWfVTt5ZvYu1OwMTgfTqkMI/XdiDsf06MKBTm4i43+WbUCIjIiIiIhIhSssr+HTjXt5dvZN3V+8iP/hwytyuqfzkij5c1rcDXdNa1V1RM6BERkRERKSRHSsrZ9nW/Xy2aS8OtE+JJyMlnvYpCbRvHU9aqzhiopvPECA5O0dKyvhgbQHvrt7J39bu5mBxGfExUVzQM4MfXHYOl/RuT1oLfPi6EhkRERGRBlZWXsGX2w/wyYZCPtlQyJIteykurcAMqptA1gzSWsWRkZJA+5T4SolOPO1bH9+WQEZKPIlxTecBhRJa2/Ye4Q+Lt/DiZ1s5WFxGu6RYxvbL5LK+HbigZzpJcS37q3zLfvciIiIiDaC8wlmz4yCfbChk0YY9fL55H0XHygDonZnCdcO6cF6PdIZ1SyUhNoqCQ8coOHSM3cFXwcFiCoqOsftgYH3tzoPsKSqhvOL0rCclPoaM1seTnZOJT/vW8WQkB3p42qfE0yYxttneK9GcuDuLN+5l5qJNvLt6F2bGuH6ZXD+iC8NyUtVTV4kSGRERkWYsOTmZoqKicIfR7Lk763YXsWj9HhZtKOTTTXs5cLQUgO4ZrZgypCMju6czontqtUOAstslkd0uqdZzVFQ4e4+UBJOb4hOJT+BnYP3LvP3sPniMo6Xlpx0fFx1Fxik9Oyd7ddprWFvYFZeW8/qy7fxu4WbW7jxEu6RYbr+wBzeM6ErHtonhDq9JUiIjIiIiIVFWVkZMTMv4auHubC48wqINe/hkQyGLNxayp6gEgM6piYzrl8nIHmmM7JFGh9ahedBgVJSRnhxPenI8fWlda2xFx8pO6eHZHezhKQj28GwuPMznm/ey70jpacdXHdZ2MtEJDGs7vt6pbaISnhDYceAof/hkC7M/28q+I6X0zkzh0asHMHlwJxJiNWywNi3jr42IiEgzcf/999O1a1fuuOMOAB5++GHMjAULFrBv3z5KS0v5xS9+weTJk+usa8eOHXznO9/h4MGDlJWV8cwzz3DBBRfw1ltv8aMf/Yjy8nLS09N5//332bt3L9/73vfYuHEjSUlJzJgxg4EDB/Lwww+Tn5/P5s2bSU9P5/HHH+f2229n69atADz22GOMGjWqQT+TxpK37wiLNhSyeEMhizYUsvNgMQCZrRO4oGdGIHHpnkbn1Np7VhqamZGSEEtKQizdM5JrLXusrJw9RSWBRKfy0LZKPT5f7TzEnqJjlFUZ1pbaKo7x/TOZOLAjw7qlEh2lYWv15e58sXUfzy3czFsrd1LhzmV9OnDLqBxGdk/TEMB6UiIjIiLyTcx7AHauCG2dmQNg/CO1Fpk6dSo/+MEPTiQyL730Em+99Rb33nsvrVu3Zs+ePYwYMYIrr7yyzi9DL7zwApdffjk//vGPKS8v58iRIxQUFHDbbbexYMECunXrxt69ewF46KGHGDJkCK+99hp/+9vfuOmmm1i2bBkAS5cu5eOPPyYxMZHvfve73HvvvZx//vls3bqVyy+/nDVr1pz9ZxMGuw8W88nGQhatL+STjYVs3XsECPRWjOiRxnnBxKVbequI/eIZHxNNp7aJdKpj6FJFhbPvSMmJRGfXgWI+Wr+Hv3yxnVmfbqV9SjxXDMxi0qCODOncNmI/j4Z2rKycN7/cwe8WbmbF9gOkJMTwvVE53DQyJ+wJcCRSIiMiIhJBhgwZwu7du8nPz6egoIB27dqRlZXFvffey4IFC4iKimL79u3s2rWLzMzMWusaOnQo3/ve9ygtLWXKlCkMHjyY+fPnM3r0aLp16wZAamoqAB9//DGvvPIKABdffDGFhYUcOHAAgCuvvJLExMAX4ffee4/Vq1efOMfBgwc5dOgQKSkpIf8sQm3v4RIWbyw8MVxsQ8FhAFonxDCiexrfG5XDyB7pnNMhucV9UY+KMtKS40lLjqdPVmDbtUM7c6SkjPfX7OaN5fnM+nQrv1u4mU5tE5k4KItJAzvSr2PrFvdZVWf3oWJmLd7KrE+3sqfoGD0yWvHzKf25akgnWsXr6/g3pU9ORETkm6ij56QhXXPNNbz88svs3LmTqVOnMmvWLAoKCli6dCmxsbHk5ORQXFxcZz2jR49mwYIFvPnmm9x4443cd999tG1b/dV0r2aO4OPlWrU6+fC9iooKPvnkkxOJTVN24Ggpn23ae2JmseNPRW8VF82wbql8Z2hnzuuRTp+s1ho2VYOkuBgmDerIpEEdOVhcyrurdvHGl/n89qNN/O+HG+me3oqJgzoyaWAWPTs0/WQ21JZv28/MRZv565f5lJY7F/duzy3n5XBBz3QleCGgREZERCTCTJ06ldtuu409e/bw4Ycf8tJLL9G+fXtiY2P54IMP2LJlS73q2bJlC506deK2227j8OHDfPHFF/z4xz/mzjvvZNOmTSeGlqWmpjJ69GhmzZrFf/zHfzB//nzS09Np3fr0G87Hjh3Lk08+yX333QfAsmXLGDx4cCjf/jd2+FgZn2/eyycbA89yWbn9ABUO8TFRDM1J5b7LOzKyRxoDOrUhVjexn7HWCbFcfW42V5+bzb7DJby1aidvLM/n//1tHU+8v47emSlMGtSRiQOzmvWT50vLK5i3ciczF27ii637SY6P4frhXbn5vBy6pTff9x0OSmREREQiTL9+/Th06BCdOnUiKyuL66+/nkmTJpGbm8vgwYPp3bt3veqZP38+v/71r4mNjSU5OZnnn3+ejIwMZsyYwVVXXUVFRQXt27fn3Xff5eGHH+bWW29l4MCBJCUl8fvf/77aOp944gnuvPNOBg4cSFlZGaNHj2b69OmhfPv1Vlxazhdb9wV7XApZvm0/ZRVObLQxpHM77r64J+f1SGNwl7bEx2h2qFBq1yqO64Z14bphXdh9sJi5K3bwxpc7+PXbX/Hrt79iUHYbJg7syBUDs5rN1MKFRceY/dlW/rB4C7sOHiMnLYmHJvXlmnOzSUmIDXd4zZJV11XcGHJzc33JkiVhObeIiASY2VJ3zw13HE1Rde3UmjVr6NOnT5gialm+yWddUlbBl3n7WbQh0OOydOs+SsoqiI4yBnRqE7g5v0cauV1TSYxT4hIO2/cf5c0v83lj+Q5WbA/cYzU0px2TBnVkfP8sMlJOf8ZOU7cq/wAzF27m9eX5lJRVcEHPdG4dlcOYc9oTpSGJZ622dko9MiIiIhKx3J2P1+9h5sLNLNpQyNHScsygb1Zrbh7ZlZE90hiak6or4k1Ep7aJTBvdg2mje7Bpz2H+ujyfv365gwdfX8XDc1YxskcakwZ2ZFz/TNomxYU73BqVlVfw3ppdPLdwM59t2ktibDT/cG42t5yX0yLvBQqXOhMZM3sOmAjsdvf+tZQbCiwGvuPuL4cuRBERETkbK1as4MYbbzxlW3x8PJ9++mmYIjp75RXO3BU7mP7hBlblH6R9SjzX5mYzskc6I7qnNukvwRLQLb0Vd1/Sk7sv6clXOw/x1y/zeWN5Pg/8ZQU/eW0lo8/JYOLALC7r26HJJKL7j5Twp8+38fwnW9i+/yjZ7RL58YQ+XJvbmTZJTSPGlqQ+PTIzgSeB52sqYGbRwKPA26EJS0REREJlwIABJ575EumKS8t5eWkev/loI1sKj9A9oxWPXj2AKUM66T6XCNYrM4Vemb344WXnsHL7wRNJzd/W7iYuJoqLe7Vn0qCOXNy7fViGBX696xAzF23mL1/kUVxawYjuqTw4qS+X9umgGe3CqM5Ext0XmFlOHcXuBl4BhoYiKBERkabK3TVtagOr7v7dA0dL+ePiLfxu4Sb2FJUwqHNb/n18H8b27aD7EJoRM2NAdhsGZLfh/nG9+fu2fbyxfAd//XIHb63aSVJcNJf26cCkQR0ZfU56gyav5RXOB2t387tFm1i4vpD4mCimDO7Ezefl0Lfj6TP2SeM763tkzKwT8H+Ai1EiIyIizVhCQgKFhYWkpaUpmWkg7k5hYSEJCQkA7DxQzHMLN/HCp1spOlbGhedkcPuFPRjRPVW/g2YuKso4t2sq53ZN5T8m9uXTTYW8sXwH81buYM7yfFISYhjXL5OJgzpyXo+0kE2ZfbC4lD8vyeP3izazde8RMlsncN/lvbhuWBdSW2nIYlMSipv9HwPud/fyuv6gmNk0YBpAly5dQnBqERGRxpOdnU1eXh4FBQXhDqVZS0hIoDShHf/28nJe/ft2yiuciQM78o8XdqdfxzbhDk/CIDrKOK9HOuf1SOdnk/vx8fo9vLE8n7dW7uTPS/NIbRXH+P6ZTBrUkaE5qd9ouNfGgiJ+v2gzLy/N43BJObld2/Fv43pxeb9MPVeoiarX9MvBoWV/re5mfzPbBBz/15IOHAGmuftrtdWp6ZdFRMJP0y/X7GzaqYPFpXz09R7G9MqgVbwmCD0Tf9+6j+kfbuCd1buIi47iO0M7c9sF3emcmhTu0KQJKi4t58OvC3hjeT7vr9nN0dJy2qfEc8XALCYN6siQzm1r7bmrqHAWrCtg5qLNzP+qgLjoKCYOyuLW87oxIFtJc1PQoNMvu3u3SieaSSDhee1s6xUREYlUH6zdzT0vLiM+JooxvTKYMCCLi3u3bzIzLzU17s6HXxfwzPwNfLppL20SY7nrom9x83k5pCdH3nNFpPEkxEZzeb9MLu+XyZGSMt5fs5s3lucza/FWfrdwM9ntEpk4sCMTB2bRr2PrE0nN4WNlvPJFHjMXbWZjwWEyUuK599Jz+O7wLhH5LJuWqj7TL88GxgDpZpYHPATEArh7eB7VKyIi0oRNHNiRDq0TmLcicIPy26sCvQsX9ExnXP9MLuvbQdMDE3gWx5srdjD9w42s2XGQrDYJ/OSKPlw3rIt6suSMJcXFMGlQRyYN6sjB4lLeWbWLN5bn85uPNjL9ww10T2/FxEEdOXKsjD8t2cah4jIGZbfhse8MZsKALOJiNHws0tRraFlD0NAyEZHwaw5Dy8ysM4FHBGQCFcAMd3+8ShkDHgcmEBgCfYu7f1FbvaFqpyoqnL9v28e8FTuZt3In2/cfJSbKGNkjjQkDshjbtwNpLazX4WhJOX9euo0ZCzaSt+8o32qfzD+O7s7kwZ30ZVJCbu/hEt5auZM3luezeFMh0WaMH5DFraNy6hx6JuFXWzulREZEpAVrJolMFpDl7l+YWQqwFJji7qsrlZlA4FEBE4DhwOPuPry2ehuinXJ3vsw7wLyVO5m3cgdbCo8QZTC8WxoTBgSGx7RvnRDSczYl+4+U8PwnW5i5aDN7D5fw7S5tuf3CHlzaR1MoS+MoOHQMMzRkMYI06D0yIiIi4eTuO4AdweVDZrYG6ASsrlRsMvC8B67eLTaztmaWFTy20ZgZgzq3ZVDnttw/rhdrdhxi3sodzF2xg/94fRUPzllFbtd2jOufxfj+mXRsm9iY4TWY/P1H+e3Hm5j92VaOlJRzce/23H5hD4bmtNPVcGlUuv+leVEiIyIizUZwls0hwKdVdnUCtlVazwtua9REpjIzo2/H1vTt2Jp/GduLdbsOMW/lTuau2MHP/7qan/91NYM6t2VC/0zG98+iS1rkzdq1btchpn+4kdeXbceBKwcFplDunamHCYrI2VMiIyIizYKZJQOvAD9w94NVd1dzyGljq8P5vLOeHVLo2SGFf76kJ5v2HGbeyh3MW7GTX81by6/mraVfx9ZMGJDFuP6Z9MhIbtTYztTSLXt5Zv5G3luzi4TYKG4Y0ZXvX9CN7HaRl4yJSNOle2RERFqw5nCPDICZxQJ/Bd529/+uZv//AvPdfXZw/StgTG1Dy5pKO7Vt7xHeCt5T88XW/QD06pDC+AGBnppzOiQ3ieFZ7s4HX+3mmfkb+HzzPtomxXLzyBxuPi9HT0MXkW9M98iIiEizFZyR7LfAmuqSmKA5wF1m9iKBm/0PNPb9Md9U59QkbhvdndtGd2fHgaO8vXInc1fu5PH31/HYe+vontGK8cHhZ5Wfk9FYSssreGN5Pv/74Ua+2nWIjm0SeGhSX74ztDNJcfqaISINR39hREQk0o0CbgRWmNmy4LYfAV3gxDPP5hKYsWw9gemXb238MM9eVptEbhnVjVtGdWP3oWLeWbWLeSsDz2F56oMNdElNYnz/TMb1z2RwA08re6SkjD99vo1nP9rE9v1HOadDMv997SAmDepIbLSmUBaRhqehZSIiLVhzGVrWECKpndp7uIR3VweeU7Nw/R5Ky52ObRICs58NyOTcLu1CNr3x3sMl/H7RZp7/ZDP7jpQyNKcdt1/Yg4t6tdcUyiISchpaJiIi0oyltorjO0O78J2hXThwtJT31+xi7oqd/PHTLTy3cBPtU+K5vF8m4wdkMiwnlZhv0GOSt+8Iz360iT99vo2jpeVc2qcD/zSmO+d2TW2AdyQiUjclMiIiIs1Im8RYrvp2Nld9O5uiY2X8be1u5q3YwZ+XbuMPi7eQ1iqOsf06ML5/FiN7pNU5DGztzoP874cbmbM8HwMmD+7EP17YnXM6pDTOGxIRqYESGRERkWYqOT6GKwd15MpBHTlSUsaHXxUwb+VO5izLZ/Zn22iTGMtlfTswYUAmo76VTnxMNBCYgezzzfuY/uEG/rZ2N0lx0dw8MofvX9Ct2TykU0QinxIZERGRFiApLobxA7IYPyCL4tJyPl63h7krd/D2qp28vDSPlPgYLu7TntycVF77+3aWbtlHaqs4fnjZOdw0sittkzSFsog0LUpkREREWpiE2Ggu7duBS/t2oKSsgkUb9jBvxU7eWb2T15flk90ukZ9e2Y9rczuTGBcd7nBFRKqlREZERKQFi4uJYkyv9ozp1Z7/r7w/6wuK+FZG8jeaEEBEpDEpkREREREAYqKj6J3ZOtxhiIjUiy63iIiIiIhIxFEiIyIiIiIiEUeJjIiIiIiIRBwlMiIiIiIiEnHqTGTM7Dkz221mK2vYf72ZfRl8LTKzQaEPU0RERERE5KT69MjMBMbVsn8TcKG7DwR+DswIQVwiIiIiIiI1qnP6ZXdfYGY5texfVGl1MZAdgrhERERERERqFOp7ZP4vMC/EdYqIiIiIiJwiZA/ENLOLCCQy59dSZhowDaBLly6hOrWIiIiIiLQwIemRMbOBwLPAZHcvrKmcu89w91x3z83IyAjFqUVEREREpAU660TGzLoAfwFudPevzz4kERERERGR2tU5tMzMZgNjgHQzywMeAmIB3H068CCQBjxtZgBl7p7bUAGLiIiIiIjUZ9ay6+rY/33g+yGLSEREREREpA6hnrVMRERERESkwSmRERERERGRiKNERkREREREIo4SGRERERERiThKZEREREREJOIokRERERERkYijREZERERERCKOEhkREREREYk4SmRERERERCTiKJEREREREZGIo0RGREREREQijhIZERERERGJOEpkREREREQk4iiRERERERGRiKNERkREREREIo4SGRERERERiThKZEREJKKZ2XNmttvMVtawf4yZHTCzZcHXg40do4iIhF5MuAMQERE5SzOBJ4HnaynzkbtPbJxwRESkMahHRkREIpq7LwD2hjsOERFpXOqREZEmrbS0lLy8PIqLi8MdSkRLSEggOzub2NjYcIcSLiPNbDmQD/yru68Kd0AiInJ26kxkzOw5YCKw2937V7PfgMeBCcAR4BZ3/yLUgYpIy5SXl0dKSgo5OTkE/tzImXJ3CgsLycvLo1u3buEOJxy+ALq6e5GZTQBeA3pWV9DMpgHTALp06dJoAYqIyJmrz9CymcC4WvaPJ9Ag9CTwx/+Zsw9LRCSguLiYtLQ0JTFnwcxIS0trsb1a7n7Q3YuCy3OBWDNLr6HsDHfPdffcjIyMRo1TRETOTJ2JTD3GHk8GnveAxUBbM8sKVYAiIkpizl5L/gzNLDM4egAzG0ag7SsMb1QiInK2QnGPTCdgW6X1vOC2HSGoW0REpFZmNhsYA6SbWR7wEBAL4O7TgWuAfzKzMuAoMNXdPUzhiohIiIRi1rLqLvNV20CY2TQzW2JmSwoKCkJwahGRhrV//36efvrpMz5uwoQJ7N+//4yPu+WWW3j55ZfP+LiWzN2vc/csd49192x3/627Tw8mMbj7k+7ez90HufsId18U7phFROTshSKRyQM6V1rPJjArzGk09lhEIk1NiUx5eXmtx82dO5e2bds2UFQiIiISiqFlc4C7zOxFYDhwwN01rExEQu6nb6xidf7BkNbZt2NrHprUr8b9DzzwABs2bGDw4MHExsaSnJxMVlYWy5YtY/Xq1UyZMoVt27ZRXFzMPffcw7Rp0wDIyclhyZIlFBUVMX78eM4//3wWLVpEp06deP3110lMTKwztvfff59//dd/paysjKFDh/LMM88QHx/PAw88wJw5c4iJiWHs2LH853/+J3/+85/56U9/SnR0NG3atGHBggUh+4xERESaovpMv1zX2OO5BKZeXk9g+uVbGypYEZHG9sgjj7By5UqWLVvG/PnzueKKK1i5cuWJaYyfe+45UlNTOXr0KEOHDuXqq68mLS3tlDrWrVvH7Nmz+c1vfsO1117LK6+8wg033FDreYuLi7nlllt4//33Oeecc7jpppt45plnuOmmm3j11VdZu3YtZnZi+NrPfvYz3n77bTp16vSNhrSJiIhEmjoTGXe/ro79DtwZsohERGpQW89JYxk2bNgpz2J54oknePXVVwHYtm0b69atOy2R6datG4MHDwbg3HPPZfPmzXWe56uvvqJbt26cc845ANx888089dRT3HXXXSQkJPD973+fK664gokTJwIwatQobrnlFq699lquuuqqELxTERGRpi0U98iIiLQYrVq1OrE8f/583nvvPT755BOWL1/OkCFDqn1WS3x8/Inl6OhoysrK6jxPTZNqxcTE8Nlnn3H11Vfz2muvMW5c4DFf06dP5xe/+AXbtm1j8ODBFBZqdmEREWneQnGPjIhIs5WSksKhQ4eq3XfgwAHatWtHUlISa9euZfHixSE7b+/evdm8eTPr16/nW9/6Fn/4wx+48MILKSoq4siRI0yYMIERI0bwrW99C4ANGzYwfPhwhg8fzhtvvMG2bdtO6xkSERFpTpTIiIjUIi0tjVGjRtG/f38SExPp0KHDiX3jxo1j+vTpDBw4kF69ejFixIiQnTchIYHf/e53/MM//MOJm/1vv/129u7dy+TJkykuLsbd+Z//+R8A7rvvPtatW4e7c8kllzBo0KCQxSIiItIUWbieCZabm+tLliwJy7lFJHKsWbOGPn36hDuMZqG6z9LMlrp7bphCatLUTomIhF9t7ZTukRERERERkYijoWUiImFw5513snDhwlO23XPPPdx6q2awFxERqQ8lMiIiYfDUU0+FOwQREZGIpqFlIiIiIiIScZTIiIiIiIhIxFEiIyIiIiIiEUeJjIhICCUnJ9e4b/PmzfTv378RoxEREWm+lMiIiIiIiEjEUSIjIlKL+++/n6effvrE+sMPP8xPf/pTLrnkEr797W8zYMAAXn/99TOut7i4mFtvvZUBAwYwZMgQPvjgAwBWrVrFsGHDGDx4MAMHDmTdunUcPnyYK664gkGDBtG/f3/+9Kc/hez9iYiIRCpNvywikWPeA7BzRWjrzBwA4x+pcffUqVP5wQ9+wB133AHASy+9xFtvvcW9995L69at2bNnDyNGjODKK6/EzOp92uPTL69YsYK1a9cyduxYvv76a6ZPn84999zD9ddfT0lJCeXl5cydO5eOHTvy5ptvAnDgwIGzeMMiIiLNg3pkRERqMWTIEHbv3k1+fj7Lly+nXbt2ZGVl8aMf/YiBAwdy6aWXsn37dnbt2nVG9X788cfceOONAPTu3ZuuXbvy9ddfM3LkSH75y1/y6KOPsmXLFhITExkwYADvvfce999/Px999BFt2rRpiLcqIiISUdQjIyKRo5aek4Z0zTXX8PLLL7Nz506mTp3KrFmzKCgoYOnSpcTGxpKTk0NxcfEZ1enu1W7/7ne/y/Dhw3nzzTe5/PLLefbZZ7n44otZunQpc+fO5d///d8ZO3YsDz74YCjemoiISMRSIiMiUoepU6dy2223sWfPHj788ENeeukl2rdvT2xsLB988AFbtmw54zpHjx7NrFmzuPjii/n666/ZunUrvXr1YuPGjXTv3p1//ud/ZuPGjXz55Zf07t2b1NRUbrjhBpKTk5k5c2bo36SIiEiEUSIjIlKHfv36cejQITp16kRWVhbXX389kyZNIjc3l8GDB9O7d+8zrvOOO+7g9ttvZ8CAAcTExDBz5kzi4+P505/+xB//+EdiY2PJzMzkwQcf5PPPP+e+++4jKiqK2NhYnnnmmQZ4lyIiIpHFahre0NByc3N9yZIlYTm3iESONWvW0KdPn3CH0SxU91ma2VJ3zw1TSE2a2ikRkfCrrZ3Szf4iIiIiIhJx6jW0zMzGAY8D0cCz7v5Ilf1tgD8CXYJ1/qe7/y7EsYqIRIQVK1acmJHsuPj4eD799NMwRSQiItL81JnImFk08BRwGZAHfG5mc9x9daVidwKr3X2SmWUAX5nZLHcvaZCoRUSasAEDBrBs2bJwhyEiItKs1Wdo2TBgvbtvDCYmLwKTq5RxIMUCT4NLBvYCZSGNVERarHDdy9ec6DMUEZHmpj6JTCdgW6X1vOC2yp4E+gD5wArgHnevCEmEItKiJSQkUFhYqC/iZ8HdKSwsJCEhIdyhiIiIhEx97pGxarZV/UZxObAMuBjoAbxrZh+5+8FTKjKbBkwD6NKlyxkHKyItT3Z2Nnl5eRQUFIQ7lIiWkJBAdnZ2uMMQEREJmfokMnlA50rr2QR6Xiq7FXjEA5dM15vZJqA38FnlQu4+A5gBgWktv2nQItJyxMbG0q1bt3CHISIiIk1MfYaWfQ70NLNuZhYHTAXmVCmzFbgEwMw6AL2AjaEMVERERERE5Lg6e2TcvczM7gLeJjD98nPuvsrMbg/unw78HJhpZisIDEW73933NGDcIiIiIiLSgtXrOTLuPheYW2Xb9ErL+cDY0IYmIiIiIiJSvfoMLRMREREREWlSlMiIiIiIiEjEUSIjIiIRzcyeM7PdZrayhv1mZk+Y2Xoz+9LMvt3YMYqISOgpkRERkUg3ExhXy/7xQM/gaxrwTCPEJCIiDUyJjIiIRDR3XwDsraXIZOB5D1gMtDWzrMaJTkREGooSGRERae46AdsqrecFt4mISARTIiMiIs2dVbPNqy1oNs3MlpjZkoKCggYOS0REzoYSGRERae7ygM6V1rOB/OoKuvsMd89199yMjIxGCU5ERL4ZJTIiItLczQFuCs5eNgI44O47wh2UiIicnZhwByAiInI2zGw2MAZIN7M84CEgFsDdpwNzgQnAeuAIcGt4IhURkVBSIiMiIhHN3a+rY78DdzZSOCIi0kg0tExERERERCKOEhkREREREYk4SmRERERERCTiKJEREREREZGIo0RGREREREQijhIZERERERGJOEpkREREREQk4iiRERERERGRiKNERkREREREIk69EhkzG2dmX5nZejN7oIYyY8xsmZmtMrMPQxumiIiIiIjISTF1FTCzaOAp4DIgD/jczOa4++pKZdoCTwPj3H2rmbVvoHhFRERERETq1SMzDFjv7hvdvQR4EZhcpcx3gb+4+1YAd98d2jBFREREREROqk8i0wnYVmk9L7itsnOAdmY238yWmtlNoQpQRERERESkqjqHlgFWzTavpp5zgUuAROATM1vs7l+fUpHZNGAaQJcuXc48WhEREREREerXI5MHdK60ng3kV1PmLXc/7O57gAXAoKoVufsMd89199yMjIxvGrOIiIiIiLRw9UlkPgd6mlk3M4sDpgJzqpR5HbjAzGLMLAkYDqwJbagiIiIiIiIBdQ4tc/cyM7sLeBuIBp5z91Vmdntw/3R3X2NmbwFfAhXAs+6+siEDFxERERGRlqs+98jg7nOBuVW2Ta+y/mvg16ELTUREREREpHr1eiCmiIiIiIhIU6JERkREREREIo4SGRERERERiThKZEREREREJOIokRERERERkYijREZERERERCKOEhkREREREYk4SmRERERERCTiKJEREREREZGIo0RGREREREQijhIZERERERGJOEpkREREREQk4iiRERERERGRiKNERkREREREIo4SGRERERERiThKZEREREREJOIokRERERERkYijREZERCKemY0zs6/MbL2ZPVDN/jFmdsDMlgVfD4YjThERCZ2YcAcgIiJyNswsGngKuAzIAz43sznuvrpK0Y/cfWKjBygiIg2iXj0ydV3pqlRuqJmVm9k1oQtRRESkVsOA9e6+0d1LgBeByWGOSUREGlidiUylK13jgb7AdWbWt4ZyjwJvhzpIERGRWnQCtlVazwtuq2qkmS03s3lm1q9xQhMRkYZSnx6Z+l7puht4BdgdwvhERETqYtVs8yrrXwBd3X0Q8P+A16qtyGyamS0xsyUFBQWhjVJEREKqPolMnVe6zKwT8H+A6aELTUREpF7ygM6V1rOB/MoF3P2guxcFl+cCsWaWXrUid5/h7rnunpuRkdGQMYuIyFmqTyJTnytdjwH3u3t5rRXpSpeIiITe50BPM+tmZnHAVGBO5QJmlmlmFlweRqD9K2z0SEVEJGTqM2tZnVe6gFzgxWAbkQ5MMLMyd3+tciF3nwHMAMjNza2aDImIiJwxdy8zs7sI3KMZDTzn7qvM7Pbg/unANcA/mVkZcBSY6u5qh0REIlh9EpkTV7qA7QSudH23cgF373Z82cxmAn+tmsSIiIg0lOBwsblVtk2vtPwk8GRjxyUiIg2nzkSmnle6REREREREGk29HohZ15WuKttvOfuwREREREREalavB2KKiIiIiIg0JUpkREREREQk4iiRERERERGRiKNERkREREREIo4SGRERERERiThKZEREREREJOIokRERERERkYijREZERERERCKOEhkREREREYk4SmRERERERCTiKJEREREREZGIo0RGREREREQijhIZERERERGJOEpkREREREQk4iiRERERERGRiBMT7gBEpImqKIeKssCrvLTSemnwZ3lwe9mpL684vS73ak5QzbZwlTtR1oO7vdJ65Z+17auuDDWXrW3fmdQXmwTn3lz9exIREWnGlMg0lPJSOHbo9FdJUeALoFeAl1ez7IFlrwiuH1+uqGH78eMraq6r2vNVKV9tXZW3OxiAgUWBBX/Wum71LG/1rK9K+TMqG4wdTl+vbtvZrldbhtqPqbp+/Pd1IpEIJg8VlZKH8rLTE4l6Jx911FXTF35pWpIzlciIiEiLpESmMncoPVop8Th4ehJSddtpZYsCP8uONlycFh34oh4VXWk5qsr24HpUVKXlSturPSa4HB0LMfFVjgmOQvSKYIJUQeCqcNX14KuivIb9NZSvcX/FyTK17a+xbMXJ321gocp6ddvqud6YomIgKjb4MzrwO4qKObkeVWk9OqbSvpjA7zIqJnhM9FnUVen46Njqy0cF/81Uy6rZVM22sJULlj2RJB//WWX7ieOrK1tXmarbazrnmdSnEcIiItIyNY9EpqK8juTieBJSTXJS9eXldZ8vKhYSWkN8SvDVGlKyIK3nqdtOLFfaFtcq8IXPrEoiUjUpqSb5iIqu5QuYhI2HMDmqvG7BJON4L5OIiIiInBCZicyKl2H+r04mH6VH6ndcbKvTk4tWGTUnHfHJ1WxLCVzhFjnulCvtIiLAvAdg54pwRyEiEn6ZA2D8Iw1Sdb0SGTMbBzwORAPPuvsjVfZfD9wfXC0C/sndl4cy0FMkpULmwGCiUV0SUk2PSFxyLUNeREREREQkktSZyJhZNPAUcBmQB3xuZnPcfXWlYpuAC919n5mNB2YAwxsiYAB6XBx4iYiINEUNdPVRREROqs9dosOA9e6+0d1LgBeByZULuPsid98XXF0MZIc2TBERERERkZPqk8h0ArZVWs8LbqvJ/wXmnU1QIiIiIiIitanPPTLV3cFc7fyzZnYRgUTm/Br2TwOmAXTp0qWeIYqIiIiIiJyqPj0yeUDnSuvZQH7VQmY2EHgWmOzuhdVV5O4z3D3X3XMzMjK+SbwiIiIiIiL1SmQ+B3qaWTcziwOmAnMqFzCzLsBfgBvd/evQhykiIiIiInJSnUPL3L3MzO4C3iYw/fJz7r7KzG4P7p8OPAikAU9b4FkaZe6e23Bhi4iIiIhIS1av58i4+1xgbpVt0ystfx/4fmhDExERERERqV59hpaJiIiIiIg0KeZe7QRkDX9iswJgy1lUkQ7sCVE4jSlS44bIjV1xNy7F3bjONu6u7q7ZV6rRgtspiNzYFXfjUtyNq6XGXWM7FbZE5myZ2ZJIvA8nUuOGyI1dcTcuxd24IjXuliCSfzeRGrviblyKu3Ep7tNpaJmIiIiIiEQcJTIiIiIiIhJxIjmRmRHuAL6hSI0bIjd2xd24FHfjitS4W4JI/t1EauyKu3Ep7saluKuI2HtkRERERESk5YrkHhkREREREWmhIjKRMbNxZvaVma03swfCHU99mNlzZrbbzFaGO5YzYWadzewDM1tjZqvM7J5wx1QfZpZgZp+Z2fJg3D8Nd0xnwsyizezvZvbXcMdyJsxss5mtMLNlZrYk3PHUl5m1NbOXzWxt8N/6yHDHVBcz6xX8nI+/DprZD8IdlwREYjsFkdlWqZ0KD7VTjUvtVA3niLShZWYWDXwNXAbkAZ8D17n76rAGVgczGw0UAc+7e/9wx1NfZpYFZLn7F2aWAiwFpkTA521AK3cvMrNY4GPgHndfHObQ6sXMfgjkAq3dfWK446kvM9sM5Lp7RM1zb2a/Bz5y92fNLA5Icvf9YQ6r3oJ/F7cDw939bJ57IiEQqe0URGZbpXYqPNRONS61U9WLxB6ZYcB6d9/o7iXAi8DkMMdUJ3dfAOwNdxxnyt13uPsXweVDwBqgU3ijqpsHFAVXY4OviMjazSwbuAJ4NtyxtARm1hoYDfwWwN1LIqlxCLoE2KAkpsmIyHYKIrOtUjvV+NRONS61UzWLxESmE7Ct0noeEfAHqzkwsxxgCPBpmEOpl2C39zJgN/Cuu0dE3MBjwL8BFWGO45tw4B0zW2pm08IdTD11BwqA3wWHSTxrZq3CHdQZmgrMDncQcoLaqTBRO9VoHkPtVGNSO1WDSExkrJptEXEFI5KZWTLwCvADdz8Y7njqw93L3X0wkA0MM7MmP0zCzCYCu919abhj+YZGufu3gfHAncFhKk1dDPBt4Bl3HwIcBiLpnoY44Ergz+GORU5QOxUGaqcah9qpsFA7VYNITGTygM6V1rOB/DDF0iIEx+6+Asxy97+EO54zFex+nQ+MC28k9TIKuDI4hvdF4GIz+2N4Q6o/d88P/twNvEpgiE1TlwfkVboS+jKBBiNSjAe+cPdd4Q5ETlA71cjUTjUqtVONT+1UDSIxkfkc6Glm3YIZ3lRgTphjaraCNyP+Fljj7v8d7njqy8wyzKxtcDkRuBRYG9ag6sHd/93ds909h8C/7b+5+w1hDqtezKxV8EZbgl3eY4EmP/ORu+8EtplZr+CmS4AmfZNwFdehYWVNjdqpRqR2qnGpnWp8aqdqFtMQlTYkdy8zs7uAt4Fo4Dl3XxXmsOpkZrOBMUC6meUBD7n7b8MbVb2MAm4EVgTH8QL8yN3nhi+keskCfh+cJSMKeMndI2qKyAjUAXg18J2CGOAFd38rvCHV293ArOCXzo3ArWGOp17MLInAzFj/GO5Y5KRIbacgYtsqtVNSX2qnGllDt1MRN/2yiIiIiIhIJA4tExERERGRFk6JjIiIiIiIRBwlMiIiIiIiEnGUyIiIiIiISMRRIiMiIiIiIhFHiYyIiIiIiEQcJTIiIiIiIhJxlMiIiIiIiEjE+f8B1S7NLz6foOsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14,4))\n",
    "axes[0].plot(epoch, loss, label='train_loss')\n",
    "axes[0].plot(epoch, val_loss, label='val_loss')\n",
    "axes[1].plot(epoch, acc, label='train_score')\n",
    "axes[1].plot(epoch, val_acc, label='val_score')\n",
    "for i in [0,1]:\n",
    "    axes[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead46a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_loss = evaluate(model, test_loader, loss_fn)\n",
    "test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609f429",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f97325",
   "metadata": {},
   "source": [
    "Видимо неверно выбрал функцию лосса. Надо работать в данном напрвлении дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220786ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
